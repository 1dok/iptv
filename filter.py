import requests
import os
import subprocess

# âœ… è®¾ç½®æ˜¯å¦å¯ç”¨åˆ†è¾¨ç‡ + ä¸‹è½½é€Ÿåº¦è¿‡æ»¤
enable_filter = False  # Falseï¼šåªåˆ¤æ–­èƒ½å¦è®¿é—®ï¼›Trueï¼šåŠ ä¸Šç”»è´¨å’Œå¸¦å®½æ£€æµ‹

min_speed_bytes = 1 * 1024 * 1024  # 1MB/s
min_width = 1280
min_height = 720
max_links_total = 1000  # æœ€å¤šå¤„ç†å¤šå°‘æ¡æµï¼ˆé˜²æ­¢è¶…æ—¶ï¼‰

sources_file = "sources.txt"
output_dir = "output"
os.makedirs(output_dir, exist_ok=True)

def is_ipv4(url):
    return '://' in url and not any(ipv6 in url for ipv6 in ['[', '::'])

# âœ… æ£€æµ‹å‡½æ•°ï¼šæ ¹æ®è®¾ç½®åˆ¤æ–­æ˜¯å¦æ£€æµ‹ç”»è´¨å’Œé€Ÿåº¦
def test_stream(url):
    try:
        if not enable_filter:
            with requests.get(url, stream=True, timeout=5) as r:
                chunk = next(r.iter_content(1024))
                if len(chunk) > 0:
                    return True
                return "é“¾æ¥æ— å“åº”"

        # ffprobe æ£€æŸ¥åˆ†è¾¨ç‡
        ffprobe_cmd = [
            "ffprobe", "-v", "error", "-select_streams", "v:0",
            "-show_entries", "stream=width,height", "-of", "csv=p=0", url
        ]
        result = subprocess.run(ffprobe_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=10)
        output = result.stdout.decode().strip()

        if not output:
            return "æ— æ³•è·å–åˆ†è¾¨ç‡"

        width, height = map(int, output.split(','))
        if width < min_width or height < min_height:
            return f"åˆ†è¾¨ç‡è¿‡ä½ï¼š{width}x{height}"

        with requests.get(url, stream=True, timeout=5) as r:
            chunk = next(r.iter_content(1024 * 512))
            if len(chunk) < 1024 * 512:
                return "é€Ÿåº¦è¿‡æ…¢"

        return True

    except Exception as e:
        return f"å¼‚å¸¸ï¼š{e}"

# âœ… ä¸»æµç¨‹ï¼šè¯»å– M3U å¹¶å¤„ç†æ‰€æœ‰æµ
filtered = []
skipped = []
stream_count = 0

with open(sources_file, 'r', encoding='utf-8') as f:
    lines = f.read().splitlines()

for i in range(len(lines)):
    if lines[i].startswith("#EXTINF") and i + 1 < len(lines):
        info = lines[i]
        url = lines[i + 1].strip()
        if not url.startswith("http") or not is_ipv4(url):
            continue

        print(f"\nğŸ¯ æ£€æµ‹æµ: {url}")
        result = test_stream(url)
        print(f"  â†’ ç»“æœ: {result}")

        if result is True:
            filtered.append(f"{info}\n{url}")
        else:
            skipped.append(f"{info}\n{url}\n# åŸå› : {result}\n")

        stream_count += 1
        if stream_count >= max_links_total:
            print("ğŸš« è¾¾åˆ°æœ€å¤§æ£€æµ‹æ•°é‡é™åˆ¶ï¼Œæå‰ç»“æŸã€‚")
            break

# âœ… å†™å…¥ç»“æœ
with open(os.path.join(output_dir, "filtered.m3u"), "w", encoding="utf-8") as f:
    f.write("#EXTM3U\n")
    f.write("\n".join(filtered) if filtered else "# æ— ç¬¦åˆæ¡ä»¶çš„ç›´æ’­æº\n")

with open(os.path.join(output_dir, "skipped.txt"), "w", encoding="utf-8") as f:
    f.write("\n".join(skipped) if skipped else "# æ‰€æœ‰ç›´æ’­æºæ£€æµ‹å¤±è´¥\n")

# âœ… æœ€ç»ˆè¾“å‡º
print(f"\nâœ… åˆæ ¼æºå†™å…¥: {len(filtered)} æ¡")
print(f"ğŸš« è¢«è·³è¿‡æº: {len(skipped)} æ¡")
print("ğŸ“ å·²å†™å…¥ output/filtered.m3u å’Œ output/skipped.txt")
