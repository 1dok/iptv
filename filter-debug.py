import requests
import re
import os
import subprocess
from collections import defaultdict

sources_file = "sources.txt"
demo_file = "demo.txt"
output_dir = "output"
min_speed_bytes = 1 * 1024 * 1024  # 1MB/s
min_width = 1280
min_height = 720
max_links_per_channel = 10

os.makedirs(output_dir, exist_ok=True)

def clean(s):
    return re.sub(r'[^a-zA-Z0-9]', '', s.lower())

with open(demo_file, 'r', encoding='utf-8') as f:
    raw_keywords = [line.strip() for line in f if line.strip() and not line.startswith("#") and "genre" not in line]
    keywords = [clean(k) for k in raw_keywords]

def is_ipv4(url):
    return '://' in url and not any(ipv6 in url for ipv6 in ['[', '::'])

def test_stream(url):
    try:
        ffprobe_cmd = [
            "ffprobe", "-v", "error", "-select_streams", "v:0",
            "-show_entries", "stream=width,height", "-of", "csv=p=0", url
        ]
        result = subprocess.run(ffprobe_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=10)
        output = result.stdout.decode().strip()
        if not output:
            return "æ— æ³•è·å–åˆ†è¾¨ç‡"
        width, height = map(int, output.split(','))
        if width < min_width or height < min_height:
            return f"åˆ†è¾¨ç‡è¿‡ä½ï¼š{width}x{height}"

        with requests.get(url, stream=True, timeout=5) as r:
            chunk = next(r.iter_content(1024 * 512))
            if len(chunk) < 1024 * 512:
                return "é€Ÿåº¦è¿‡æ…¢"
            return True
    except Exception as e:
        return f"å¼‚å¸¸ï¼š{e}"

candidates = defaultdict(list)
match_count = defaultdict(int)
filtered = []
skipped = []

with open(sources_file, 'r', encoding='utf-8') as f:
    src_urls = [line.strip() for line in f if line.strip() and not line.startswith("#")]

for src in src_urls:
    print(f"\nğŸ“¥ æ­£åœ¨æŠ“å–æº: {src}")
    try:
        res = requests.get(src, timeout=10)
        lines = res.text.splitlines()
        print(f"âœ… è·å–æˆåŠŸï¼Œå…± {len(lines)} è¡Œ")

        for i in range(len(lines)):
            if lines[i].startswith("#EXTINF") and i + 1 < len(lines):
                info_line = lines[i]
                url = lines[i + 1].strip()
                if not url.startswith("http") or not is_ipv4(url):
                    continue

                cleaned_info = clean(info_line)
                for idx, kw in enumerate(keywords):
                    if kw in cleaned_info:
                        print(f"ğŸ¯ å‘½ä¸­å…³é”®è¯: {raw_keywords[idx]} â†’ {info_line.strip()}")
                        match_count[kw] += 1
                        if len(candidates[kw]) < max_links_per_channel:
                            candidates[kw].append((info_line, url))
                        break
    except Exception as e:
        print(f"âš ï¸ æºæŠ“å–å¤±è´¥: {e}")

# æµ‹è¯•æµ
for kw, streams in candidates.items():
    print(f"\nğŸ” æµ‹è¯•é¢‘é“å…³é”®è¯: {kw}ï¼ˆå€™é€‰ {len(streams)} æ¡ï¼‰")
    count = 0
    for info, url in streams:
        print(f"  â†’ æµ‹è¯•é“¾æ¥: {url}")
        print(f"    æ ‡é¢˜: {info}")
        result = test_stream(url)
        print(f"    æµ‹è¯•ç»“æœ: {result} ({type(result)})")
        if result is True:
            filtered.append(f"{info}\n{url}")
            count += 1
        else:
            skipped.append(f"{info}\n{url}\n# åŸå› : {result}\n")
        if count >= max_links_per_channel:
            break

# å†™å…¥æ–‡ä»¶
filtered_file = os.path.join(output_dir, "filtered.m3u")
skipped_file = os.path.join(output_dir, "skipped.txt")

with open(filtered_file, "w", encoding="utf-8") as f:
    f.write("#EXTM3U\n")
    if filtered:
        f.write("\n".join(filtered))
    else:
        f.write("# æ— ç¬¦åˆæ¡ä»¶çš„ç›´æ’­æº\n")

with open(skipped_file, "w", encoding="utf-8") as f:
    if skipped:
        f.write("\n".join(skipped))
    else:
        f.write("# æ‰€æœ‰é¢‘é“æ£€æµ‹å‡æœªå‘½ä¸­æˆ–æµ‹é€Ÿå¤±è´¥\n")

# æ€»ç»“è¾“å‡º
print("\nğŸ“Š åŒ¹é…é¢‘é“ç»Ÿè®¡ï¼š")
for raw, kw in zip(raw_keywords, keywords):
    print(f"  - {raw} åŒ¹é…æµæ•°: {match_count[kw]}")

print(f"\nâœ… åˆæ ¼æºå†™å…¥: {len(filtered)} æ¡")
print(f"ğŸš« ä¸åˆæ ¼å†™å…¥: {len(skipped)} æ¡")
print("ğŸ“ å·²å†™å…¥ output/filtered.m3u å’Œ output/skipped.txt")
